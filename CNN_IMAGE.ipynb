{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1e00c4da-1ec9-4402-a28b-6ad4b241b3a8",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"IMAGE CLASSIFICATION THROUGH NEURAL NETWORK\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692228a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.mkdir('models')\n",
    "    \n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Is using GPU?', tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d13916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_classes(x, y):\n",
    "    indices_0, _ = np.where(y == 0.)\n",
    "    indices_1, _ = np.where(y == 1.)\n",
    "    indices_2, _ = np.where(y == 2.)\n",
    "\n",
    "\n",
    "    indices = np.concatenate([indices_0, indices_1, indices_2], axis=0)\n",
    "    \n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    count = x.shape[0]\n",
    "    indices = np.random.choice(range(count), count, replace=False)\n",
    "    \n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, y_train = get_three_classes(x_train, y_train)\n",
    "x_test, y_test = get_three_classes(x_test, y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['aeroplane', 'car', 'bird']\n",
    "\n",
    "def show_random_examples(x, y, p):\n",
    "    indices = np.random.choice(range(x.shape[0]), 10, replace = False)\n",
    "    \n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    p = p[indices]\n",
    "    \n",
    "    plt.figure(figsize = (10, 5))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, 1 + i)\n",
    "        plt.imshow(x[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        col = 'green' if np.argmax(y[i]) == np.argmax(p[i]) else 'red'\n",
    "        plt.xlabel(class_names[np.argmax(p[i])], color = col)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "show_random_examples(x_train, y_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_examples(x_test, y_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ccb31",
   "metadata": {},
   "source": [
    "## CREATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Input, Dense\n",
    "\n",
    "def create_model():\n",
    "    def add_conv_block(model, num_filters):\n",
    "        model.add(Conv2D(num_filters, 3, activation = 'relu', padding = 'same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(num_filters, 3, activation = 'relu'))\n",
    "        model.add(MaxPooling2D(pool_size = 2))\n",
    "        model.add(Dropout(0.5))\n",
    "        return model\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Input(shape = (32, 32, 3))) # Check -- its not input()-- Input() is used to instantiate a Keras tensor\n",
    "\n",
    "    model = add_conv_block(model, 32)\n",
    "    model = add_conv_block(model, 64)\n",
    "    model = add_conv_block(model, 128)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3 , activation = 'softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer = 'adam', \n",
    "        metrics = ['accuracy']\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(\n",
    "    x_train/225., y_train,\n",
    "    validation_data = (x_train/225., y_train),\n",
    "    epochs = 10, batch_size = 128,\n",
    "    callbacks = [\n",
    "                 tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 3),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(\n",
    "                     '/content/models/model_{val_accuracy:.3f}.h5', save_best_only = True,\n",
    "                      save_weights_only = False, moniter = 'val_accuracy'\n",
    "                                                    )\n",
    "                 ]\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = h.history['accuracy']\n",
    "val_accs = h.history['val_accuracy']\n",
    "\n",
    "plt.plot(range(len(accs)), accs, label = 'Training')\n",
    "plt.plot(range(len(accs)), val_accs, label ='Validation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83389727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/models/model_0.912.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea61cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb01fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd35075c",
   "metadata": {},
   "source": [
    "## KEY POINTS\n",
    "\n",
    "Neural networks learn features directly from data by which they are trained, so most specialists don’t need to extract features manually.\n",
    "\n",
    "“The power of neural networks comes from their ability to learn the representation in your training data and how to best relate it to the output variable that you want to predict in your project. In this sense, neural networks learn through mapping. Mathematically, they are capable of learning any kind of mapping function and have been proven to be universal approximation algorithms .\n",
    "\n",
    "The training data, in this case, is a large dataset that contains many examples of each image class. When we say a large dataset, we really mean it. For instance, the ImageNet dataset contains more than 14 million human-annotated images representing 21,841 concepts (synonym sets or synsets according to the WordNet hierarchy), with 1,000 images per concept on average.\n",
    "\n",
    "Each image is annotated (labeled) with a category it belongs to – a cat or dog. The algorithm explores these examples, learns about the visual characteristics of each category, and eventually learns how to recognize each image class. This model training style is called supervised learning.\n",
    "\n",
    "Each layer of nodes trains on the output (feature set) produced by the previous layer. So, nodes in each successive layer can recognize more complex, detailed features – visual representations of what the image depicts. Such a “hierarchy of increasing complexity and abstraction” is known as feature hierarchy.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
